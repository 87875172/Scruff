% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tenxqc.R
\name{tenxqc}
\alias{tenxqc}
\title{Generate and output 10X read alignment data quality metrics}
\usage{
tenxqc(bam, experiment, validCb = NA, filter = NA, yieldSize = 1e+06,
  outDir = "./", cores = max(1, parallel::detectCores() - 2))
}
\arguments{
\item{bam}{Paths to input BAM files generated by Cell Ranger pipeline. These
files are usually named \emph{"possorted_genome_bam.bam"} in the
 \emph{"outs"} folder of the top-level project output folders, respectively.}

\item{experiment}{A character vector of experiment names. Represents the
group label for each BAM file, e.g. "patient1, patient2, ...". The
length of \code{experiment} equals the number of BAM files to be processed.}

\item{validCb}{Path to the cell barcode whitelist file. By default is
\code{NA} which uses file "737K-august-2016.txt". Can be inspected by
calling \code{data(validCb, package = "scruff")}.}

\item{filter}{Paths to the filtered barcode files. Should be same length and
order of the input BAM files. These files are named
\emph{"barcodes.tsv"} located at
\emph{outs/filtered_gene_bc_matrices/<reference_genome>/}. Default is
\code{NA} meaning no filtering is applied.}

\item{yieldSize}{The number of records (alignments) to yield when drawing
successive subsets from a BAM file, providing the number of successive 
records to be returned on each yield. This parameter is passed to the
\code{yieldSize} argument of the \code{BamFile} function in
\emph{Rsamtools} package. Default is \strong{1e06}.}

\item{outDir}{Output directory. The location to write resulting QC table.}

\item{cores}{Number of cores used for parallelization. Default is
\code{max(1, parallel::detectCores() - 2)}, i.e. the number of available
cores minus 2.}
}
\value{
ggplot object showing the number of aligned reads and reads aligned
 to an gene.
}
\description{
Read BAM file generated by Cell Ranger pipeline and generate QC metrics
 including number of aligned reads and reads aligned to an gene.
}
